{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzero.buffer_utils import Buffer\n",
    "from muzero.config import PLANE_NUM, MuZeroConfig\n",
    "from muzero.self_play import SelfPlay\n",
    "from muzero.buffer_utils import make_target\n",
    "import xqcpp\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fen = \"3k5/2P1P4/9/9/9/9/9/9/4p1p2/5K3 r - 100 0 190\"\n",
    "# init_fen = \"2r2k3/6R1C/b4N1rb/9/5n3/5C3/6n2/5p3/4p4/5K1R1 r - 110 0 180\"\n",
    "config = MuZeroConfig()\n",
    "config.batch_size = 128\n",
    "config.training_steps = 200\n",
    "config.num_simulations = 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = Buffer(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzero.models import MuZeroNetwork\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from muzero.trainer_utils import update_weights, update_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MuZeroNetwork(config)\n",
    "model.to(\"cuda\")\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=config.lr_init,\n",
    "    momentum=config.momentum,\n",
    "    weight_decay=config.weight_decay,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selfplay():\n",
    "    pass\n",
    "players = [SelfPlay(config, i, init_fen) for i in range(16)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_time = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0nth loss [total:35.24 value:0.20 reward:0.05 policy:35.14] lr:0.00200 duration:77.41420\n",
      "     10nth loss [total:3.77 value:0.04 reward:0.05 policy:3.71] lr:0.00200 duration:8.67228\n",
      "     20nth loss [total:2.32 value:0.04 reward:0.02 policy:2.29] lr:0.00200 duration:6.89903\n",
      "     30nth loss [total:1.06 value:0.05 reward:0.01 policy:1.05] lr:0.00188 duration:6.59749\n",
      "     40nth loss [total:0.60 value:0.03 reward:0.00 policy:0.59] lr:0.00176 duration:8.60835\n",
      "     50nth loss [total:0.86 value:0.01 reward:0.00 policy:0.86] lr:0.00164 duration:7.01295\n",
      "     60nth loss [total:0.61 value:0.00 reward:0.00 policy:0.61] lr:0.00153 duration:6.73122\n",
      "     70nth loss [total:0.32 value:0.00 reward:0.00 policy:0.32] lr:0.00141 duration:5.85175\n",
      "     80nth loss [total:0.50 value:0.00 reward:0.00 policy:0.50] lr:0.00129 duration:5.99368\n",
      "     90nth loss [total:0.44 value:0.00 reward:0.00 policy:0.44] lr:0.00117 duration:6.20480\n",
      "    100nth loss [total:0.50 value:0.00 reward:0.00 policy:0.50] lr:0.00105 duration:6.48190\n",
      "    110nth loss [total:0.23 value:0.00 reward:0.00 policy:0.23] lr:0.00093 duration:5.99300\n",
      "    120nth loss [total:0.27 value:0.00 reward:0.00 policy:0.27] lr:0.00081 duration:6.84066\n",
      "    130nth loss [total:0.49 value:0.00 reward:0.00 policy:0.49] lr:0.00069 duration:6.00618\n",
      "    140nth loss [total:0.65 value:0.00 reward:0.00 policy:0.65] lr:0.00057 duration:6.77390\n",
      "    150nth loss [total:0.19 value:0.00 reward:0.00 policy:0.19] lr:0.00046 duration:6.03720\n",
      "    160nth loss [total:0.51 value:0.00 reward:0.00 policy:0.50] lr:0.00034 duration:6.38579\n",
      "    170nth loss [total:0.27 value:0.00 reward:0.00 policy:0.27] lr:0.00022 duration:6.48002\n",
      "    180nth loss [total:0.13 value:0.00 reward:0.00 policy:0.13] lr:0.00010 duration:6.06587\n",
      "    190nth loss [total:0.38 value:0.00 reward:0.01 policy:0.38] lr:0.00010 duration:5.83487\n"
     ]
    }
   ],
   "source": [
    "for training_step in range(config.training_steps):\n",
    "    start = time.time()\n",
    "    player = random.choice(players)\n",
    "    gh = player.rollout(model, training_step)\n",
    "    buffer.save_game(gh)\n",
    "    index_batch, batch = buffer.get_batch()\n",
    "    # 训练\n",
    "    # model.to(\"cuda\")\n",
    "    model.train()\n",
    "    (\n",
    "        total_loss,\n",
    "        value_loss,\n",
    "        reward_loss,\n",
    "        policy_loss,\n",
    "    ) = update_weights(batch, model, optimizer, config, False)\n",
    "    update_lr(training_step, optimizer, config)\n",
    "    if training_step % 10 == 0:\n",
    "        batch_time += time.time() - start\n",
    "        print(\n",
    "            \"{:>7d}nth loss [total:{:.2f} value:{:.2f} reward:{:.2f} policy:{:.2f}] lr:{:.5f} duration:{:.5f}\".format(\n",
    "                training_step,\n",
    "                total_loss,\n",
    "                value_loss,\n",
    "                reward_loss,\n",
    "                policy_loss,\n",
    "                optimizer.param_groups[0][\"lr\"],\n",
    "                batch_time,\n",
    "            )\n",
    "        )\n",
    "        batch_time = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存储模型\n",
    "torch.save(model.get_weights(), \"model_weights.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
